### **README.md Actualizado con la Documentación de los Challenges**

# **Visualización de Grandes Bases de Datos**

## **Descripción**
Este repositorio contiene evidencia y materiales desarrollados en el marco de la asignatura **"Visualización de Grandes Bases de Datos"**, parte del plan de estudios de la **Maestría en Ciencia de los Datos** de la **Universidad de Guadalajara**. El repositorio incluye actividades prácticas diseñadas para explorar el uso de **PySpark** en la manipulación y análisis de grandes bases de datos, con un enfoque en el aprendizaje progresivo a través de tres desafíos: básico, intermedio y avanzado.

---

## **Objetivo Final del Producto**
El objetivo principal de este repositorio es consolidar y demostrar los conocimientos adquiridos en la asignatura mediante la resolución de tres desafíos prácticos. Cada challenge permite aplicar habilidades específicas en la visualización y análisis de datos, usando enfoques reproducibles y eficientes en un entorno de Big Data. Estos desafíos reflejan una progresión en la complejidad de las tareas y las herramientas utilizadas:

1. Familiarización con PySpark y Koalas.
2. Aplicación de algoritmos de machine learning con Spark ML.
3. Análisis avanzado utilizando APIs avanzadas de PySpark, relacionado con temas de investigación de tesis.

---

## **Justificación y Relevancia**
La capacidad de manejar grandes volúmenes de datos es fundamental en la era del Big Data. Este repositorio demuestra la relevancia de dominar herramientas como PySpark para abordar problemas reales en ciencia de datos. Los desafíos aquí documentados reflejan la importancia de traducir conceptos teóricos en aplicaciones prácticas y escalables, destacando la preparación de los estudiantes para enfrentar retos en la industria y la academia.

---

## **Contenido del Repositorio**
### **Challenge 1: Introducción a PySpark y Koalas**
- **Descripción**: Este primer desafío introduce a los estudiantes al uso de PySpark y Koalas para trabajar con grandes bases de datos, emulando la sintaxis de pandas en un entorno distribuido.
- **Objetivo**: Realizar un análisis exploratorio utilizando la **Global Terrorism Database** obtenida de Kaggle.
- **Actividades**:
  - Descargar y cargar los datos en Databricks.
  - Realizar transformaciones básicas con Koalas.
  - Crear visualizaciones simples usando PySpark y librerías de Python como Matplotlib y Plotly.
- **Métricas de evaluación**:
  - Corrección en la carga de datos (20%).
  - Uso adecuado de Koalas (30%).
  - Visualizaciones básicas (30%).
  - Limpieza y organización del código (20%).

---

### **Challenge 2: Modelado con Spark ML**
- **Descripción**: En este desafío, los estudiantes aplican técnicas de machine learning con Spark ML para resolver un problema de clasificación.
- **Objetivo**: Construir un modelo predictivo que clasifique la calidad del vino utilizando el **Wine Quality Dataset** del UCI Machine Learning Repository.
- **Actividades**:
  - Descargar y preparar los datos.
  - Entrenar un modelo de regresión logística con Spark ML.
  - Documentar los resultados en GitHub.
- **Métricas de evaluación**:
  - Limpieza y preparación de los datos (20%).
  - Selección adecuada del modelo (20%).
  - Exactitud y calidad de la evaluación (30%).
  - Documentación clara (30%).

---

### **Challenge 3: Análisis Avanzado con PySpark**
- **Descripción**: Este último desafío relaciona el análisis de grandes bases de datos con el tema de tesis de cada estudiante.
- **Objetivo**: Realizar un análisis avanzado utilizando PySpark, empleando APIs como Spark Streaming o Spark ML para análisis en tiempo real o construcción de modelos predictivos.
- **Actividades**:
  - Seleccionar una base de datos relevante (ej., datos del Banco Mundial).
  - Usar Spark Streaming o Spark ML para realizar un análisis detallado.
  - Crear una presentación y documentar los resultados en GitHub.
- **Métricas de evaluación**:
  - Relación clara con el tema de tesis (20%).
  - Uso avanzado de PySpark (25%).
  - Análisis detallado y conclusiones (25%).
  - Calidad de la presentación (20%).
  - Organización del código en GitHub (10%).

---

Este README.md documenta no solo los contenidos, sino también el propósito de cada actividad, destacando su impacto en el aprendizaje y desarrollo profesional de nosotros como estudiantes. 

