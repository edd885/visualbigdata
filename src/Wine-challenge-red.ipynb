{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0fa503a-413d-4e4c-afdc-9b67f80d9b8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Wine Quality notebook\n",
    "Calidad de vino predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae891c34-2b1d-48b3-b4da-f8956917bb50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[9]: [Table(name='wine1', catalog='spark_catalog', namespace=['default'], description=None, tableType='EXTERNAL', isTemporary=False),\n Table(name='winequality_red_3_csv', catalog='spark_catalog', namespace=['default'], description=None, tableType='EXTERNAL', isTemporary=False)]"
     ]
    }
   ],
   "source": [
    "# Para ver todas las bases de datos\n",
    "spark.catalog.listDatabases()\n",
    "\n",
    "# Para ver todas las tablas en la base de datos actual\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6adb9f49-6b84-4205-83c1-afd9a0889179",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[11]: Row(fixed acidity=7.4, volatile acidity=0.7, citric acid=0.0, residual sugar=1.9, chlorides=0.076, free sulfur dioxide=11.0, total sulfur dioxide=34.0, density=0.9978, pH=3.51, sulphates=0.56, alcohol=9.4, quality=5)"
     ]
    }
   ],
   "source": [
    "df = spark.table(\"wine1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55a22409-c82e-431d-ae82-c57e41723236",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases de calidad:\n+-------+-----+\n|quality|count|\n+-------+-----+\n|      3|   10|\n|      4|   53|\n|      5|  681|\n|      6|  638|\n|      7|  199|\n|      8|   18|\n+-------+-----+\n\n\nEntrenando el modelo...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Cargar los datos\n",
    "df = spark.table(\"wine1\")\n",
    "\n",
    "# Verificar clases únicas en la variable target\n",
    "print(\"Distribución de clases de calidad:\")\n",
    "df.groupBy(\"quality\").count().orderBy(\"quality\").show()\n",
    "\n",
    "# Seleccionar las características (features)\n",
    "feature_cols = [\n",
    "    \"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\",\n",
    "    \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\",\n",
    "    \"pH\", \"sulphates\", \"alcohol\"\n",
    "]\n",
    "\n",
    "# Crear el pipeline de preprocesamiento y modelo\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"assembled_features\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"assembled_features\",\n",
    "    outputCol=\"features\",\n",
    "    withStd=True,\n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "# Ajustando parámetros del Random Forest con valores válidos\n",
    "rf = RandomForestClassifier(\n",
    "    labelCol=\"quality\",\n",
    "    featuresCol=\"features\",\n",
    "    numTrees=100,\n",
    "    maxDepth=10,\n",
    "    seed=42,\n",
    "    bootstrap=True\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, scaler, rf])\n",
    "\n",
    "# Dividir los datos\n",
    "train_data, test_data = df.randomSplit([0.75, 0.25], seed=42)\n",
    "\n",
    "# Crear una cuadrícula de parámetros con valores válidos\n",
    "paramGrid = (ParamGridBuilder()\n",
    "    .addGrid(rf.numTrees, [50, 100, 200])\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15])\n",
    "    .addGrid(rf.minInstancesPerNode, [1, 2, 4])\n",
    "    .addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt', 'log2'])\n",
    "    .build())\n",
    "\n",
    "# Evaluadores\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"quality\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"quality\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "# Configurar la validación cruzada\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator_accuracy,\n",
    "    numFolds=5,\n",
    "    parallelism=2\n",
    ")\n",
    "\n",
    "print(\"\\nEntrenando el modelo...\")\n",
    "cv_model = crossval.fit(train_data)\n",
    "\n",
    "predictions = cv_model.transform(test_data)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "print(f\"\\nMétricas de evaluación:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Matriz de confusión con porcentajes\n",
    "print(\"\\nMatriz de confusión (con porcentajes):\")\n",
    "confusion_matrix = predictions.groupBy(\"quality\", \"prediction\").count()\n",
    "total_by_actual = predictions.groupBy(\"quality\").count().withColumnRenamed(\"count\", \"total\")\n",
    "confusion_matrix_pct = confusion_matrix.join(total_by_actual, \"quality\") \\\n",
    "    .withColumn(\"percentage\", (confusion_matrix.count / total_by_actual.total) * 100)\n",
    "confusion_matrix_pct.orderBy(\"quality\", \"prediction\").show()\n",
    "\n",
    "# Mejores parámetros\n",
    "best_model = cv_model.bestModel.stages[-1]\n",
    "print(\"\\nMejores parámetros encontrados:\")\n",
    "print(f\"Número de árboles: {best_model.getNumTrees}\")\n",
    "print(f\"Profundidad máxima: {best_model.getMaxDepth}\")\n",
    "print(f\"Instancias mínimas por nodo: {best_model.getMinInstancesPerNode}\")\n",
    "print(f\"Estrategia de subconjunto de características: {best_model.getFeatureSubsetStrategy}\")\n",
    "\n",
    "# Importancia de características\n",
    "feature_importance = best_model.featureImportances\n",
    "print(\"\\nImportancia de características (ordenadas por importancia):\")\n",
    "feature_importances = list(zip(feature_cols, feature_importance))\n",
    "feature_importances.sort(key=lambda x: x[1], reverse=True)\n",
    "for feature, importance in feature_importances:\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "# Ejemplos de predicciones\n",
    "print(\"\\nEjemplos de predicciones con probabilidades:\")\n",
    "predictions.select(\"quality\", \"prediction\", \"probability\").show(5, truncate=False)\n",
    "\n",
    "# Métricas por clase\n",
    "print(\"\\nMétricas por clase:\")\n",
    "for label in predictions.select(\"quality\").distinct().collect():\n",
    "    label_value = label.quality\n",
    "    label_predictions = predictions.withColumn(\"is_correct\", \n",
    "        (predictions.quality == predictions.prediction).cast(\"double\"))\n",
    "    \n",
    "    label_metrics = label_predictions.filter(predictions.quality == label_value)\n",
    "    accuracy_class = label_metrics.select(\"is_correct\").mean().collect()[0][0]\n",
    "    \n",
    "    print(f\"Clase {label_value}:\")\n",
    "    print(f\"Accuracy: {accuracy_class:.4f}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91020752-4ebe-4dc4-b84d-3f4ba0a34d72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases de calidad:\n+-------+-----+\n|quality|count|\n+-------+-----+\n|      3|   10|\n|      4|   53|\n|      5|  681|\n|      6|  638|\n|      7|  199|\n|      8|   18|\n+-------+-----+\n\n\nEntrenando el modelo...\n\nMétricas de evaluación:\nAccuracy: 0.6690\nF1 Score: 0.6548\n\nMatriz de confusión:\n+-------+----------+-----+\n|quality|prediction|count|\n+-------+----------+-----+\n|      3|       4.0|    1|\n|      3|       5.0|    2|\n|      4|       5.0|    4|\n|      4|       6.0|    3|\n|      5|       5.0|  149|\n|      5|       6.0|   47|\n|      5|       7.0|    1|\n|      6|       5.0|   29|\n|      6|       6.0|  113|\n|      6|       7.0|   12|\n|      7|       5.0|    2|\n|      7|       6.0|   32|\n|      7|       7.0|   23|\n|      8|       6.0|    7|\n|      8|       7.0|    1|\n+-------+----------+-----+\n\n\nImportancia de características (ordenadas por importancia):\nalcohol: 0.1833\nsulphates: 0.1132\nvolatile acidity: 0.0976\nfixed acidity: 0.0972\ntotal sulfur dioxide: 0.0961\ndensity: 0.0836\nchlorides: 0.0762\npH: 0.0696\nfree sulfur dioxide: 0.0665\ncitric acid: 0.0611\nresidual sugar: 0.0556\n\nEjemplos de predicciones:\n+-------+----------+--------------------+\n|quality|prediction|         probability|\n+-------+----------+--------------------+\n|      7|       6.0|[0.0,0.0,0.0,0.0,...|\n|      6|       6.0|[0.0,0.0,0.0,0.0,...|\n|      5|       6.0|[0.0,0.0,0.0,0.0,...|\n|      7|       6.0|[0.0,0.0,0.0,0.0,...|\n|      5|       5.0|[0.0,0.0,0.0,0.02...|\n+-------+----------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Cargar los datos\n",
    "df = spark.table(\"wine1\")\n",
    "\n",
    "# Verificar clases únicas en la variable target\n",
    "print(\"Distribución de clases de calidad:\")\n",
    "df.groupBy(\"quality\").count().orderBy(\"quality\").show()\n",
    "\n",
    "# Seleccionar las características (features)\n",
    "feature_cols = [\n",
    "    \"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\",\n",
    "    \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\",\n",
    "    \"pH\", \"sulphates\", \"alcohol\"\n",
    "]\n",
    "\n",
    "# Crear el pipeline de preprocesamiento y modelo\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"assembled_features\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"assembled_features\",\n",
    "    outputCol=\"features\",\n",
    "    withStd=True,\n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "# Configurar el Random Forest con parámetros predefinidos\n",
    "rf = RandomForestClassifier(\n",
    "    labelCol=\"quality\",\n",
    "    featuresCol=\"features\",\n",
    "    numTrees=50,\n",
    "    maxDepth=10,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Crear el pipeline\n",
    "pipeline = Pipeline(stages=[assembler, scaler, rf])\n",
    "\n",
    "# Dividir los datos\n",
    "train_data, test_data = df.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"\\nEntrenando el modelo...\")\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluar el modelo\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"quality\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"quality\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "print(f\"\\nMétricas de evaluación:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Matriz de confusión\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "predictions.groupBy(\"quality\", \"prediction\").count().orderBy(\"quality\", \"prediction\").show()\n",
    "\n",
    "# Importancia de características\n",
    "rf_model = model.stages[-1]\n",
    "feature_importance = rf_model.featureImportances\n",
    "print(\"\\nImportancia de características (ordenadas por importancia):\")\n",
    "feature_importances = list(zip(feature_cols, feature_importance))\n",
    "feature_importances.sort(key=lambda x: x[1], reverse=True)\n",
    "for feature, importance in feature_importances:\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "# Ejemplos de predicciones\n",
    "print(\"\\nEjemplos de predicciones:\")\n",
    "predictions.select(\"quality\", \"prediction\", \"probability\").show(5)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Wine-challenge-red",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
